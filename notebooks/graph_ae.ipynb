{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a28e5-1496-4302-b1c7-7e08d1b3c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "libs_path = os.path.abspath(os.path.join(current_dir, \"..\", \"libs\"))\n",
    "if libs_path not in sys.path:\n",
    "    sys.path.append(libs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56db4b97-0920-4c77-8df3-e8647818a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "pd.set_option('display.precision', 3)\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac6cebd-d5f3-4c1f-b19e-cb7404d4cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d917bc462c4461fac67e2c3eb531ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Датасеты:', layout=Layout(width='500px'), options={'.ipynb_checkpoints': 'E:\\\\stud…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425ef5fb1c9d4d61917283e434bc5880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='ОК', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddc4c8541d245329956d564389f83f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=dp.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f91320b-f0ab-4fe6-b7ab-0149fdce616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fn in res.options:\n",
    "    if res.options[fn] not in res.value:\n",
    "        continue\n",
    "    df = dp.Dataset(pd.read_excel(res.options[fn]), name=fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2f2934-ce2f-4e6d-9df3-30016d4041e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Конфигурация (Dataclass)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Конфигурация модели и обучения.\"\"\"\n",
    "    # Данные\n",
    "    window_size: int = 10\n",
    "    num_nodes: int = 5  # Количество признаков (колонок)\n",
    "    \n",
    "    # Архитектура\n",
    "    input_dim: int = 1\n",
    "    embed_dim: int = 32       # Размерность эмбеддинга\n",
    "    hidden_dim: int = 64      # Размерность скрытых слоев\n",
    "    latent_dim: int = 16      # Размерность латентного вектора\n",
    "    num_heads: int = 4        # Количество голов внимания\n",
    "    num_layers: int = 2       # Количество слоев энкодера/декодера\n",
    "    dropout: float = 0.2\n",
    "    \n",
    "    # Граф\n",
    "    use_learnable_graph: bool = True\n",
    "    graph_reg_lambda: float = 1e-4  # Коэффициент регуляризации графа (спарсность)\n",
    "    \n",
    "    # Обучение\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-5\n",
    "    device: str = \"auto\"      # \"cuda\", \"cpu\" или \"auto\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Слои Архитектуры\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Позиционное кодирование для временных шагов.\"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0) # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (Batch, Time, Nodes, Dim) -> нужно применить по времени\n",
    "        # Для упрощения применим к измерению Time, предполагая, что Nodes независимы в позиции\n",
    "        # Транспонируем для совместимости с классическим PE\n",
    "        b, t, n, d = x.shape\n",
    "        x = x + self.pe[:, :t, :d].unsqueeze(2) # (B, T, 1, D) broadcast to (B, T, N, D)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Исправленные слои Архитектуры\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class TemporalSelfAttention(nn.Module):\n",
    "    \"\"\"Внимание по временной оси (Multi-Head).\"\"\"\n",
    "    def __init__(self, dim: int, num_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (Batch, Time, Nodes, Dim)\n",
    "        b, t, n, d = x.shape\n",
    "        # Переставляем: (Batch * Nodes, Time, Dim)\n",
    "        # .contiguous() важен после permute\n",
    "        x = x.permute(0, 2, 1, 3).contiguous().view(-1, t, d)\n",
    "        \n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Возвращаем форму: (Batch, Time, Nodes, Dim)\n",
    "        # .contiguous() перед view для безопасности\n",
    "        x = x.view(b, n, t, d).permute(0, 2, 1, 3).contiguous()\n",
    "        return x\n",
    "\n",
    "class SpatialGraphAttention(nn.Module):\n",
    "    \"\"\"Внимание по оси признаков (Графовый слой с обучаемой смежностью).\"\"\"\n",
    "    def __init__(self, dim: int, num_nodes: int, dropout: float = 0.1, use_learnable: bool = True):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.use_learnable = use_learnable\n",
    "        \n",
    "        if self.use_learnable:\n",
    "            # Обучаемые эмбеддинги узлов для вычисления внимания\n",
    "            self.node_embeddings = nn.Parameter(torch.Tensor(num_nodes, dim))\n",
    "            nn.init.xavier_uniform_(self.node_embeddings)\n",
    "        \n",
    "        self.w_q = nn.Linear(dim, dim)\n",
    "        self.w_k = nn.Linear(dim, dim)\n",
    "        self.w_v = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        # x: (Batch, Time, Nodes, Dim)\n",
    "        b, t, n, d = x.shape\n",
    "        \n",
    "        # Вычисляем матрицу внимания A (N, N)\n",
    "        if self.use_learnable:\n",
    "            # Attention Score = Softmax(Emb * Emb^T)\n",
    "            adj = torch.matmul(self.node_embeddings, self.node_embeddings.T)\n",
    "            adj = F.softmax(adj, dim=1)\n",
    "        else:\n",
    "            # Полносвязный граф (все со всеми)\n",
    "            adj = torch.ones(n, n, device=x.device) / n\n",
    "            \n",
    "        adj_matrix = adj # Для регуляризации\n",
    "        \n",
    "        # Применяем внимание к признакам\n",
    "        # x: (B, T, N, D) -> (B*T, N, D)\n",
    "        # ИСПРАВЛЕНИЕ: используем reshape вместо view для неконтинуальных тензоров\n",
    "        x_flat = x.reshape(-1, n, d)\n",
    "        \n",
    "        Q = self.w_q(x_flat)\n",
    "        K = self.w_k(x_flat)\n",
    "        V = self.w_v(x_flat)\n",
    "        \n",
    "        # Graph Attention: A * V\n",
    "        # Нужно расширить adj до батча\n",
    "        adj_batch = adj.unsqueeze(0).expand(b * t, -1, -1)\n",
    "        \n",
    "        out = torch.matmul(adj_batch, V)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Residual\n",
    "        out = out + x_flat\n",
    "        out = self.norm(out)\n",
    "        \n",
    "        # ИСПРАВЛЕНИЕ: reshape при возврате формы\n",
    "        return out.reshape(b, t, n, d), adj_matrix\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Исправленная Основная Модель (Decoder Fix)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class SpatioTemporalGAE(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_nodes = config.num_nodes\n",
    "        self.window_size = config.window_size\n",
    "        \n",
    "        # Input Projection\n",
    "        self.input_proj = nn.Linear(config.input_dim, config.embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(config.embed_dim, config.window_size, config.dropout)\n",
    "        \n",
    "        # Encoder Stack\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderBlock(config.embed_dim, config.num_nodes, config.num_heads, config.dropout, config.use_learnable_graph)\n",
    "            for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Bottleneck (Latent Space)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim * config.num_nodes, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_dim, config.latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder Stack (Symmetric)\n",
    "        self.decoder_proj = nn.Linear(config.latent_dim, config.hidden_dim)\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            EncoderBlock(config.embed_dim, config.num_nodes, config.num_heads, config.dropout, config.use_learnable_graph)\n",
    "            for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output Projection\n",
    "        self.output_proj = nn.Linear(config.embed_dim, config.input_dim)\n",
    "        \n",
    "        # ИСПРАВЛЕНИЕ: Выносим линейный слой декодера в __init__\n",
    "        # Ранее он создавался в forward, что ломало граф вычислений и регистр параметров\n",
    "        self.decoder_expand = nn.Linear(config.hidden_dim, config.embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        x: (Batch, Time, Nodes)\n",
    "        Returns: reconstruction, latent_vector, graph_loss\n",
    "        \"\"\"\n",
    "        b, t, n = x.shape\n",
    "        assert n == self.num_nodes, f\"Expected {self.num_nodes} nodes, got {n}\"\n",
    "        assert t == self.window_size, f\"Expected window {self.window_size}, got {t}\"\n",
    "        \n",
    "        # 1. Embedding\n",
    "        x = x.unsqueeze(-1) # (B, T, N, 1)\n",
    "        x = self.input_proj(x) # (B, T, N, Embed)\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        # 2. Encoder\n",
    "        adj_reg_loss = 0.0\n",
    "        for layer in self.encoder_layers:\n",
    "            x, adj = layer(x)\n",
    "            if self.config.use_learnable_graph and self.config.graph_reg_lambda > 0:\n",
    "                # L1 regularization for sparsity\n",
    "                adj_reg_loss += torch.norm(adj, 1)\n",
    "        \n",
    "        # 3. Latent Space\n",
    "        # Flatten (N, Embed) -> Vector\n",
    "        x_flat = x.reshape(b, t, -1) # (B, T, N*Embed)\n",
    "        # Global Pooling over Time (Mean)\n",
    "        x_pool = x_flat.mean(dim=1) # (B, N*Embed)\n",
    "        latent = self.bottleneck(x_pool) # (B, Latent)\n",
    "        \n",
    "        # 4. Decoder\n",
    "        # Expand latent back to (B, T, N, Embed)\n",
    "        dec_h = self.decoder_proj(latent) # (B, Hidden)\n",
    "        # Repeat for Time steps\n",
    "        dec_h = dec_h.unsqueeze(1).repeat(1, t, 1) # (B, T, Hidden)\n",
    "        # Project to Embed dim and reshape to Nodes\n",
    "        # ИСПРАВЛЕНИЕ: используем предопределенный слой decoder_expand\n",
    "        dec_h = dec_h.unsqueeze(2).repeat(1, 1, n, 1) # (B, T, N, Hidden)\n",
    "        x = self.decoder_expand(dec_h) # (B, T, N, Embed)\n",
    "        \n",
    "        # Pass through Decoder Layers\n",
    "        for layer in self.decoder_layers:\n",
    "            x, _ = layer(x)\n",
    "            \n",
    "        # 5. Output\n",
    "        recon = self.output_proj(x) # (B, T, N, 1)\n",
    "        recon = recon.squeeze(-1) # (B, T, N)\n",
    "        \n",
    "        return recon, latent, adj_reg_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_nodes: int, num_heads: int, dropout: float, use_learnable_graph: bool):\n",
    "        super().__init__()\n",
    "        self.temporal_attn = TemporalSelfAttention(dim, num_heads, dropout)\n",
    "        self.spatial_attn = SpatialGraphAttention(dim, num_nodes, dropout, use_learnable_graph)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "        self.norm_ffn = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.temporal_attn(x)\n",
    "        x_spatial, adj = self.spatial_attn(x)\n",
    "        \n",
    "        # FFN\n",
    "        out = self.ffn(x_spatial)\n",
    "        out = out + x_spatial\n",
    "        out = self.norm_ffn(out)\n",
    "        return out, adj\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Основная Модель (Factory Pattern)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def create_advanced_gae(config: ModelConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Фабричная функция для создания модели, оптимизатора и потерь.\n",
    "    \"\"\"\n",
    "    device = config.device\n",
    "    if device == \"auto\":\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    model = SpatioTemporalGAE(config).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.learning_rate, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # MSE для реконструкции\n",
    "    criterion_rec = nn.MSELoss(reduction='none')\n",
    "    # MSE для латентного пространства (если нужно сравнивать с центроидом)\n",
    "    criterion_lat = nn.MSELoss()\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"criterion_rec\": criterion_rec,\n",
    "        \"criterion_lat\": criterion_lat,\n",
    "        \"device\": device,\n",
    "        \"config\": config\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Тренер и Детектор Аномалий\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class GraphAnomalyDetector:\n",
    "    def __init__(self, df: pd.DataFrame, config: ModelConfig):\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.config.num_nodes = df.shape[1] # Авто-определение узлов\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model_dict = create_advanced_gae(self.config)\n",
    "        self.train_stats = {}\n",
    "\n",
    "    def _prepare_data(self, df: pd.DataFrame, fit_scaler: bool = False) -> np.ndarray:\n",
    "        data = df.values\n",
    "        if fit_scaler:\n",
    "            data = self.scaler.fit_transform(data)\n",
    "        else:\n",
    "            data = self.scaler.transform(data)\n",
    "            \n",
    "        n_samples = data.shape[0] - self.config.window_size + 1\n",
    "        windows = np.zeros((n_samples, self.config.window_size, data.shape[1]))\n",
    "        for i in range(n_samples):\n",
    "            windows[i] = data[i : i + self.config.window_size]\n",
    "        return windows.astype(np.float32)\n",
    "\n",
    "    def fit(self, epochs: int = 100, batch_size: int = 64, verbose: bool = True):\n",
    "        model = self.model_dict[\"model\"]\n",
    "        optimizer = self.model_dict[\"optimizer\"]\n",
    "        criterion_rec = self.model_dict[\"criterion_rec\"]\n",
    "        device = self.model_dict[\"device\"]\n",
    "        config = self.model_dict[\"config\"]\n",
    "        \n",
    "        train_data = self._prepare_data(self.df, fit_scaler=True)\n",
    "        tensor_data = torch.FloatTensor(train_data).to(device)\n",
    "        dataset = torch.utils.data.TensorDataset(tensor_data)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            total_rec_loss = 0\n",
    "            total_graph_loss = 0\n",
    "            \n",
    "            for batch in loader:\n",
    "                x = batch[0]\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                recon, latent, graph_reg = model(x)\n",
    "                \n",
    "                # Reconstruction Loss\n",
    "                rec_loss = criterion_rec(recon, x).mean()\n",
    "                \n",
    "                # Total Loss\n",
    "                loss = rec_loss + (config.graph_reg_lambda * graph_reg)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_rec_loss += rec_loss.item()\n",
    "                total_graph_loss += graph_reg.item()\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f} | Rec: {total_rec_loss/len(loader):.4f}\")\n",
    "        \n",
    "        # Сохраняем статистику обучения для порога\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            recon, latent, _ = model(tensor_data)\n",
    "            errors = criterion_rec(recon, tensor_data).mean(dim=(1, 2)).cpu().numpy()\n",
    "            self.train_stats['mean_error'] = np.mean(errors)\n",
    "            self.train_stats['std_error'] = np.std(errors)\n",
    "            self.train_stats['threshold'] = np.percentile(errors, 95) # Default 95%\n",
    "\n",
    "    def detect(self, threshold_percentile: float = 95.0) -> pd.DataFrame:\n",
    "        model = self.model_dict[\"model\"]\n",
    "        criterion_rec = self.model_dict[\"criterion_rec\"]\n",
    "        device = self.model_dict[\"device\"]\n",
    "        \n",
    "        model.eval()\n",
    "        data_windows = self._prepare_data(self.df, fit_scaler=False)\n",
    "        tensor_data = torch.FloatTensor(data_windows).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            recon, latent, _ = model(tensor_data)\n",
    "            \n",
    "            # 1. Reconstruction Error\n",
    "            rec_errors = criterion_rec(recon, tensor_data).mean(dim=(1, 2)).cpu().numpy()\n",
    "            \n",
    "            # 2. Latent Deviation (Optional robustness check)\n",
    "            # Можно сравнивать с центроидом латентного пространства обучения\n",
    "            # Для простоты используем только Rec Error + сглаживание\n",
    "            \n",
    "        # Маппинг ошибок обратно на временную ось\n",
    "        # Окно i покрывает точки [i, i+T-1]. Приписываем ошибку центру окна или концу.\n",
    "        full_scores = np.zeros(len(self.df))\n",
    "        mid_point = self.config.window_size // 2\n",
    "        \n",
    "        for i, err in enumerate(rec_errors):\n",
    "            idx = i + mid_point\n",
    "            if idx < len(full_scores):\n",
    "                # Накопление ошибок (если точка попадает в несколько окон)\n",
    "                full_scores[idx] += err\n",
    "                # В реальной реализации нужно делить на количество покрытий, \n",
    "                # но для детекции пиков это не критично.\n",
    "        \n",
    "        # Нормализация скоринга (простая)\n",
    "        # Заполняем края\n",
    "        full_scores[:mid_point] = full_scores[mid_point]\n",
    "        full_scores[-mid_point:] = full_scores[-mid_point-1]\n",
    "        \n",
    "        # Динамический порог\n",
    "        threshold = np.percentile(rec_errors, threshold_percentile)\n",
    "        # Для полного ряда используем статистику обучения, если тестовый похож\n",
    "        anomaly_mask = full_scores > (self.train_stats['mean_error'] + 3 * self.train_stats['std_error'])\n",
    "        \n",
    "        # Переопределяем маску на основе конкретного порога запроса, если нужно\n",
    "        # Здесь используем комбинированный подход:\n",
    "        final_threshold = np.percentile(full_scores, threshold_percentile)\n",
    "        anomaly_mask = full_scores > final_threshold\n",
    "        \n",
    "        result = self.df.copy()\n",
    "        result['anomaly_score'] = full_scores\n",
    "        result['is_anomaly'] = anomaly_mask\n",
    "        \n",
    "        return result, final_threshold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5794253f-4bde-4a9f-81cb-b75b9e092ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: auto\n",
      "Data Shape: (2399, 53)\n",
      "\n",
      "Training Model...\n",
      "Epoch 10/100 | Loss: 0.9691 | Rec: 0.9585\n",
      "Epoch 20/100 | Loss: 0.8205 | Rec: 0.8099\n",
      "Epoch 30/100 | Loss: 0.8019 | Rec: 0.7913\n",
      "Epoch 40/100 | Loss: 0.7568 | Rec: 0.7462\n",
      "Epoch 50/100 | Loss: 0.7481 | Rec: 0.7375\n",
      "Epoch 60/100 | Loss: 0.7687 | Rec: 0.7581\n",
      "Epoch 70/100 | Loss: 0.7482 | Rec: 0.7376\n",
      "Epoch 80/100 | Loss: 0.7435 | Rec: 0.7329\n",
      "Epoch 90/100 | Loss: 0.7444 | Rec: 0.7338\n",
      "Epoch 100/100 | Loss: 0.7427 | Rec: 0.7321\n"
     ]
    }
   ],
   "source": [
    "# 2. Конфигурация\n",
    "config = ModelConfig(\n",
    "    window_size=50,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=128,\n",
    "    latent_dim=32,\n",
    "    num_heads=8,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    learning_rate=1e-3,\n",
    "    graph_reg_lambda=1e-4, # Штраф за сложные графы\n",
    "    device=\"auto\"\n",
    ")\n",
    "    \n",
    "print(f\"Running on: {config.device}\")\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "\n",
    "# 3. Инициализация и Обучение\n",
    "detector = GraphAnomalyDetector(df, config)\n",
    "    \n",
    "print(\"\\nTraining Model...\")\n",
    "detector.fit(epochs=100, batch_size=64, verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f5a308-77f5-471c-9633-d741c1f181a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detecting Anomalies...\n",
      "\n",
      "Threshold: 3.0933\n",
      "Detected 216 anomalies.\n",
      "\n",
      "Top 5 Anomaly Scores:\n",
      "       Ubs,V  Ibs,A  Isun,A  Ipt1,A  Ipt2,A  Ipt3,A  Ipt4,A  Ipt5,A  Ipt6,A  \\\n",
      "1955  11.029   4.51    3.81    0.69    3.22    0.76    3.20    3.38    4.73   \n",
      "1956  11.037   4.51    3.81    3.18    3.22    3.24    3.20    3.38    4.73   \n",
      "1954  11.020   4.51    3.81    3.18    3.22    3.22    3.20    3.38    4.73   \n",
      "1957  11.055   4.51    3.81    3.18    3.22    3.24    3.20    3.38    4.73   \n",
      "1958  11.090   4.51    3.81    3.18    3.29    3.24    3.22    3.38    4.73   \n",
      "\n",
      "      Ipt7,A  ...  TNap,C  TPrd2,C  TPrd1,C  TDS24,C  power, W       D+  \\\n",
      "1955    3.76  ...    -128     -128        6      -23    49.740  357.084   \n",
      "1956    3.76  ...    -128     -128        6       52    49.779  355.758   \n",
      "1954    3.76  ...    -128     -128        6      -23    49.700  357.084   \n",
      "1957    3.76  ...    -128     -128        6       52    49.858  355.758   \n",
      "1958    3.76  ...    -128     -128        6       52    50.016  355.758   \n",
      "\n",
      "           D-        D  anomaly_score  is_anomaly  \n",
      "1955  333.282  488.453         31.574        True  \n",
      "1956  294.228  461.664         31.484        True  \n",
      "1954  295.900  463.752         31.465        True  \n",
      "1957  294.228  461.664         31.434        True  \n",
      "1958  297.027  463.453         31.358        True  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDetecting Anomalies...\")\n",
    "result_df, threshold = detector.detect(threshold_percentile=91.0)\n",
    "    \n",
    "print(f\"\\nThreshold: {threshold:.4f}\")\n",
    "anomalies = result_df[result_df['is_anomaly']]\n",
    "print(f\"Detected {len(anomalies)} anomalies.\")\n",
    "print(\"\\nTop 5 Anomaly Scores:\")\n",
    "print(result_df.nlargest(5, 'anomaly_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56acd538-1a05-43f4-81e9-3bf7a369e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2076  113]\n",
      " [ 107  103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2189\n",
      "           1       0.48      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.91      2399\n",
      "   macro avg       0.71      0.72      0.72      2399\n",
      "weighted avg       0.91      0.91      0.91      2399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "print(confusion_matrix(df[\"Class\"], result_df['is_anomaly']))\n",
    "print(classification_report(df[\"Class\"], result_df['is_anomaly']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "682e03ee-9a32-46a5-9c40-b4092c1ca37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 216\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Class\"].sum(), result_df['is_anomaly'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0812b5c-8d19-407b-91a8-df660a82d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2389</th>\n",
       "      <th>2390</th>\n",
       "      <th>2391</th>\n",
       "      <th>2392</th>\n",
       "      <th>2393</th>\n",
       "      <th>2394</th>\n",
       "      <th>2395</th>\n",
       "      <th>2396</th>\n",
       "      <th>2397</th>\n",
       "      <th>2398</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_anomaly</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "is_anomaly     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "Class          0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "            2389  2390  2391  2392  2393  2394  2395  2396  2397  2398  \n",
       "is_anomaly     0     0     0     0     0     0     0     0     0     0  \n",
       "Class          0     1     1     1     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 2399 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92b9366f-24a6-4272-a2c5-fecb7027d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel(\"graph_ae_res.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694ee19-5c2f-44cd-828e-9732f372383b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
